#!/usr/bin/env python3
"""
PB Product Generator - Output Cleanup Script
ìë™ìœ¼ë¡œ ì˜¤ë˜ëœ output íŒŒì¼ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
"""

import os
import shutil
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Tuple


def get_dir_size(path: Path) -> int:
    """ë””ë ‰í† ë¦¬ í¬ê¸° ê³„ì‚° (bytes)"""
    total = 0
    for entry in path.rglob('*'):
        if entry.is_file():
            total += entry.stat().st_size
    return total


def format_size(bytes_size: int) -> str:
    """ë°”ì´íŠ¸ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if bytes_size < 1024.0:
            return f"{bytes_size:.1f} {unit}"
        bytes_size /= 1024.0
    return f"{bytes_size:.1f} TB"


def get_dated_folders(output_dir: Path) -> List[Tuple[Path, datetime]]:
    """ë‚ ì§œë³„ í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (YYYYMMDD í˜•ì‹)"""
    folders = []
    for item in output_dir.iterdir():
        if item.is_dir() and item.name.isdigit() and len(item.name) == 8:
            try:
                date = datetime.strptime(item.name, "%Y%m%d")
                folders.append((item, date))
            except ValueError:
                continue
    return sorted(folders, key=lambda x: x[1])


def get_old_html_files(output_dir: Path, days: int) -> List[Tuple[Path, datetime]]:
    """ë£¨íŠ¸ì˜ ì˜¤ë˜ëœ HTML íŒŒì¼ ëª©ë¡"""
    cutoff = datetime.now() - timedelta(days=days)
    old_files = []

    for item in output_dir.iterdir():
        if item.is_file() and item.suffix in ['.html', '.htm']:
            mtime = datetime.fromtimestamp(item.stat().st_mtime)
            if mtime < cutoff:
                old_files.append((item, mtime))

    return sorted(old_files, key=lambda x: x[1])


def cleanup_by_age(output_dir: Path, days: int, dry_run: bool = False) -> Tuple[int, int]:
    """ì˜¤ë˜ëœ íŒŒì¼/í´ë” ì‚­ì œ"""
    cutoff = datetime.now() - timedelta(days=days)
    deleted_count = 0
    freed_bytes = 0

    print(f"\nğŸ—‘ï¸  ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬ (ê¸°ì¤€: {days}ì¼ ì´ì „)\n")
    print(f"   ê¸°ì¤€ ë‚ ì§œ: {cutoff.strftime('%Y-%m-%d %H:%M:%S')}\n")

    # ë‚ ì§œë³„ í´ë” ì‚­ì œ
    folders = get_dated_folders(output_dir)
    for folder, date in folders:
        if date < cutoff:
            size = get_dir_size(folder)
            if dry_run:
                print(f"   [DRY RUN] ì‚­ì œ ì˜ˆì •: {folder.name}/ ({format_size(size)})")
            else:
                print(f"   ì‚­ì œ ì¤‘: {folder.name}/ ({format_size(size)})")
                shutil.rmtree(folder)
            deleted_count += 1
            freed_bytes += size

    # ë£¨íŠ¸ì˜ ì˜¤ë˜ëœ HTML íŒŒì¼ ì‚­ì œ
    old_files = get_old_html_files(output_dir, days)
    for file_path, mtime in old_files:
        size = file_path.stat().st_size
        if dry_run:
            print(f"   [DRY RUN] ì‚­ì œ ì˜ˆì •: {file_path.name} ({format_size(size)})")
        else:
            print(f"   ì‚­ì œ ì¤‘: {file_path.name} ({format_size(size)})")
            file_path.unlink()
        deleted_count += 1
        freed_bytes += size

    return deleted_count, freed_bytes


def cleanup_by_size(output_dir: Path, max_size_mb: int, dry_run: bool = False) -> Tuple[int, int]:
    """í¬ê¸° ì œí•œ ê¸°ë°˜ ì •ë¦¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ)"""
    max_bytes = max_size_mb * 1024 * 1024
    current_size = get_dir_size(output_dir)

    if current_size <= max_bytes:
        print(f"\nâœ… í˜„ì¬ í¬ê¸° {format_size(current_size)} â‰¤ ìµœëŒ€ í¬ê¸° {format_size(max_bytes)}")
        print("   ì •ë¦¬ ë¶ˆí•„ìš”\n")
        return 0, 0

    print(f"\nğŸ—‘ï¸  í¬ê¸° ê¸°ë°˜ ì •ë¦¬ (ìµœëŒ€: {format_size(max_bytes)})\n")
    print(f"   í˜„ì¬ í¬ê¸°: {format_size(current_size)}")
    print(f"   ì´ˆê³¼ í¬ê¸°: {format_size(current_size - max_bytes)}\n")

    deleted_count = 0
    freed_bytes = 0

    # ì˜¤ë˜ëœ ë‚ ì§œ í´ë”ë¶€í„° ì‚­ì œ
    folders = get_dated_folders(output_dir)
    for folder, date in folders:
        if current_size - freed_bytes <= max_bytes:
            break

        size = get_dir_size(folder)
        if dry_run:
            print(f"   [DRY RUN] ì‚­ì œ ì˜ˆì •: {folder.name}/ ({format_size(size)})")
        else:
            print(f"   ì‚­ì œ ì¤‘: {folder.name}/ ({format_size(size)})")
            shutil.rmtree(folder)
        deleted_count += 1
        freed_bytes += size

    # ì•„ì§ ì´ˆê³¼í•˜ë©´ ë£¨íŠ¸ì˜ ì˜¤ë˜ëœ HTMLë„ ì‚­ì œ
    if current_size - freed_bytes > max_bytes:
        old_files = get_old_html_files(output_dir, days=0)  # ëª¨ë“  íŒŒì¼
        for file_path, mtime in old_files:
            if current_size - freed_bytes <= max_bytes:
                break

            size = file_path.stat().st_size
            if dry_run:
                print(f"   [DRY RUN] ì‚­ì œ ì˜ˆì •: {file_path.name} ({format_size(size)})")
            else:
                print(f"   ì‚­ì œ ì¤‘: {file_path.name} ({format_size(size)})")
                file_path.unlink()
            deleted_count += 1
            freed_bytes += size

    return deleted_count, freed_bytes


def show_stats(output_dir: Path, cache_dir: Path):
    """output í´ë” ë° ìºì‹œ í†µê³„ í‘œì‹œ"""
    output_exists = output_dir.exists()
    cache_exists = cache_dir.exists()

    if not output_exists and not cache_exists:
        print(f"âŒ Output ë° ìºì‹œ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    print("\n" + "=" * 60)
    print("ğŸ“Š ìŠ¤í† ë¦¬ì§€ í†µê³„")
    print("=" * 60)

    total_size = 0

    # Output í´ë” í†µê³„
    if output_exists:
        output_size = get_dir_size(output_dir)
        total_size += output_size
        folders = get_dated_folders(output_dir)
        html_files = list(output_dir.glob('*.html'))

        print(f"\nğŸ“ Output í´ë”: {output_dir}")
        print(f"ğŸ’¾ í¬ê¸°: {format_size(output_size)}")
        print(f"ğŸ“… ë‚ ì§œë³„ í´ë”: {len(folders)}ê°œ")
        print(f"ğŸ“„ ë£¨íŠ¸ HTML íŒŒì¼: {len(html_files)}ê°œ")

        if folders:
            print("\nğŸ“… ë‚ ì§œë³„ í´ë” ìƒì„¸:")
            for folder, date in folders:
                size = get_dir_size(folder)
                age_days = (datetime.now() - date).days
                print(f"   {folder.name}/ - {format_size(size):>10} ({age_days}ì¼ ì „)")

        if html_files:
            print("\nğŸ“„ ë£¨íŠ¸ HTML íŒŒì¼:")
            for file_path in html_files:
                size = file_path.stat().st_size
                mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                age_days = (datetime.now() - mtime).days
                print(f"   {file_path.name} - {format_size(size):>10} ({age_days}ì¼ ì „)")

    # Cache í´ë” í†µê³„
    if cache_exists:
        cache_size = get_dir_size(cache_dir)
        total_size += cache_size
        cache_files = list(cache_dir.glob('*.json'))

        print(f"\nğŸ“¦ ìºì‹œ í´ë”: {cache_dir}")
        print(f"ğŸ’¾ í¬ê¸°: {format_size(cache_size)}")
        print(f"ğŸ“„ ìºì‹œ íŒŒì¼: {len(cache_files)}ê°œ")

        if cache_files and len(cache_files) <= 10:
            print("\nğŸ“„ ìºì‹œ íŒŒì¼:")
            for file_path in cache_files:
                size = file_path.stat().st_size
                mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                age_days = (datetime.now() - mtime).days
                print(f"   {file_path.name} - {format_size(size):>10} ({age_days}ì¼ ì „)")
        elif cache_files:
            print(f"\n   (ì´ {len(cache_files)}ê°œ íŒŒì¼ - ëª©ë¡ ìƒëµ)")

    print(f"\nğŸ’¾ ì „ì²´ í¬ê¸°: {format_size(total_size)}")
    print("\n" + "=" * 60 + "\n")


def cleanup_cache(cache_dir: Path, days: int = 0, dry_run: bool = False) -> Tuple[int, int]:
    """ìºì‹œ íŒŒì¼ ì •ë¦¬ (.cache/figma)

    Args:
        cache_dir: ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        days: Nì¼ ì´ìƒ ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ (0ì´ë©´ ì „ì²´)
        dry_run: ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ

    Returns:
        Tuple[int, int]: (ì‚­ì œëœ íŒŒì¼ ìˆ˜, í™•ë³´ëœ ë°”ì´íŠ¸)
    """
    if not cache_dir.exists():
        print(f"â„¹ï¸  ìºì‹œ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {cache_dir}")
        return 0, 0

    deleted_count = 0
    freed_bytes = 0

    print(f"\nğŸ—‘ï¸  ìºì‹œ ì •ë¦¬ ({cache_dir})\n")

    if days > 0:
        cutoff = datetime.now() - timedelta(days=days)
        print(f"   ê¸°ì¤€ ë‚ ì§œ: {cutoff.strftime('%Y-%m-%d %H:%M:%S')}\n")

    # JSON ìºì‹œ íŒŒì¼ ì •ë¦¬
    cache_files = list(cache_dir.glob('*.json'))

    for file_path in cache_files:
        # ë‚ ì§œ ê¸°ì¤€ì´ ìˆìœ¼ë©´ ì²´í¬
        if days > 0:
            mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
            if mtime >= cutoff:
                continue

        size = file_path.stat().st_size
        if dry_run:
            print(f"   [DRY RUN] ì‚­ì œ ì˜ˆì •: {file_path.name} ({format_size(size)})")
        else:
            print(f"   ì‚­ì œ ì¤‘: {file_path.name} ({format_size(size)})")
            file_path.unlink()
        deleted_count += 1
        freed_bytes += size

    return deleted_count, freed_bytes


def cleanup_all(output_dir: Path, cache_dir: Path, dry_run: bool = False) -> Tuple[int, int]:
    """ì „ì²´ ì‚­ì œ (output í´ë” + ìºì‹œ ì „ì²´)"""
    total_count = 0
    total_size = 0

    # Output í´ë”
    if output_dir.exists():
        output_size = get_dir_size(output_dir)
        output_count = sum(1 for _ in output_dir.rglob('*') if _.is_file())
        total_count += output_count
        total_size += output_size

    # Cache í´ë”
    if cache_dir.exists():
        cache_size = get_dir_size(cache_dir)
        cache_count = sum(1 for _ in cache_dir.rglob('*') if _.is_file())
        total_count += cache_count
        total_size += cache_size

    if total_count == 0:
        print(f"â„¹ï¸  ì‚­ì œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n")
        return 0, 0

    if dry_run:
        print(f"\n[DRY RUN] ì „ì²´ ì‚­ì œ ì˜ˆì •: {total_count}ê°œ íŒŒì¼, {format_size(total_size)}\n")
        if output_dir.exists():
            print(f"   Output: {output_count}ê°œ íŒŒì¼, {format_size(output_size)}")
        if cache_dir.exists():
            print(f"   Cache: {cache_count}ê°œ íŒŒì¼, {format_size(cache_size)}")
        print()
        return total_count, total_size

    print(f"\nâš ï¸  ê²½ê³ : output ë° ìºì‹œ í´ë” ì „ì²´ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤!")
    print(f"   ì´ íŒŒì¼ ìˆ˜: {total_count}ê°œ")
    print(f"   ì´ í¬ê¸°: {format_size(total_size)}\n")
    if output_dir.exists():
        print(f"   Output: {output_count}ê°œ íŒŒì¼, {format_size(output_size)}")
    if cache_dir.exists():
        print(f"   Cache: {cache_count}ê°œ íŒŒì¼, {format_size(cache_size)}")
    print()

    response = input("ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ")
    if response.lower() != 'yes':
        print("\nì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.\n")
        return 0, 0

    deleted_count = 0
    deleted_size = 0

    # Output ì‚­ì œ
    if output_dir.exists():
        shutil.rmtree(output_dir)
        output_dir.mkdir(exist_ok=True)
        deleted_count += output_count
        deleted_size += output_size
        print(f"âœ… Output ì‚­ì œ ì™„ë£Œ: {output_count}ê°œ íŒŒì¼")

    # Cache ì‚­ì œ
    if cache_dir.exists():
        shutil.rmtree(cache_dir)
        cache_dir.mkdir(exist_ok=True)
        deleted_count += cache_count
        deleted_size += cache_size
        print(f"âœ… Cache ì‚­ì œ ì™„ë£Œ: {cache_count}ê°œ íŒŒì¼")

    print(f"\nâœ… ì „ì²´ ì‚­ì œ ì™„ë£Œ: {deleted_count}ê°œ íŒŒì¼, {format_size(deleted_size)} í™•ë³´\n")

    return deleted_count, deleted_size


def main():
    parser = argparse.ArgumentParser(
        description="PB Product Generator Output & Cache Cleanup",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  %(prog)s --stats                    # í†µê³„ë§Œ í‘œì‹œ
  %(prog)s --days 7                   # 7ì¼ ì´ìƒ ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ
  %(prog)s --days 7 --dry-run         # ì‚­ì œ ì˜ˆì • ëª©ë¡ë§Œ í‘œì‹œ
  %(prog)s --max-size 500             # 500MBë¡œ í¬ê¸° ì œí•œ
  %(prog)s --cache --days 7           # ìºì‹œë§Œ ì •ë¦¬ (7ì¼ ì´ìƒ)
  %(prog)s --cache                    # ìºì‹œ ì „ì²´ ì •ë¦¬
  %(prog)s --all                      # ì „ì²´ ì‚­ì œ (output + cache)
  %(prog)s --all --dry-run            # ì „ì²´ ì‚­ì œ ì‹œë®¬ë ˆì´ì…˜
        """
    )

    parser.add_argument(
        '--output-dir',
        type=str,
        default='output',
        help='Output ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸: output/)'
    )
    parser.add_argument(
        '--cache-dir',
        type=str,
        default='.cache/figma',
        help='ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸: .cache/figma/)'
    )
    parser.add_argument(
        '--stats',
        action='store_true',
        help='í†µê³„ë§Œ í‘œì‹œí•˜ê³  ì¢…ë£Œ'
    )
    parser.add_argument(
        '--days',
        type=int,
        help='Nì¼ ì´ìƒ ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ'
    )
    parser.add_argument(
        '--max-size',
        type=int,
        help='ìµœëŒ€ í¬ê¸° (MB) - ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ'
    )
    parser.add_argument(
        '--cache',
        action='store_true',
        help='ìºì‹œ íŒŒì¼ë§Œ ì •ë¦¬ (--daysì™€ í•¨ê»˜ ì‚¬ìš© ê°€ëŠ¥)'
    )
    parser.add_argument(
        '--all',
        action='store_true',
        help='ì „ì²´ ì‚­ì œ (output + cache, í™•ì¸ í•„ìš”)'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ì‹¤ì œ ì‚­ì œí•˜ì§€ ì•Šê³  ì‹œë®¬ë ˆì´ì…˜ë§Œ ì‹¤í–‰'
    )

    args = parser.parse_args()
    output_dir = Path(args.output_dir)
    cache_dir = Path(args.cache_dir)

    print("\n" + "ğŸš€ PB Product Generator - Storage Cleanup")
    print("=" * 60)

    # í†µê³„ í‘œì‹œ
    if args.stats:
        show_stats(output_dir, cache_dir)
        return

    # ì „ì²´ ì‚­ì œ
    if args.all:
        count, size = cleanup_all(output_dir, cache_dir, dry_run=args.dry_run)
        return

    # ìºì‹œë§Œ ì •ë¦¬
    if args.cache:
        count, size = cleanup_cache(cache_dir, days=args.days or 0, dry_run=args.dry_run)
        if count > 0:
            print(f"\nâœ… ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {count}ê°œ íŒŒì¼, {format_size(size)} í™•ë³´\n")
        else:
            print(f"\nâœ… ì •ë¦¬í•  ìºì‹œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n")
        return

    # ë‚ ì§œ ê¸°ë°˜ ì •ë¦¬ (outputë§Œ)
    if args.days:
        count, size = cleanup_by_age(output_dir, args.days, dry_run=args.dry_run)
        if count > 0:
            print(f"\nâœ… ì •ë¦¬ ì™„ë£Œ: {count}ê°œ í•­ëª©, {format_size(size)} í™•ë³´\n")
        else:
            print(f"\nâœ… ì •ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\n")
        return

    # í¬ê¸° ê¸°ë°˜ ì •ë¦¬ (outputë§Œ)
    if args.max_size:
        count, size = cleanup_by_size(output_dir, args.max_size, dry_run=args.dry_run)
        if count > 0:
            print(f"\nâœ… ì •ë¦¬ ì™„ë£Œ: {count}ê°œ í•­ëª©, {format_size(size)} í™•ë³´\n")
        return

    # ì˜µì…˜ ì—†ìœ¼ë©´ ë„ì›€ë§ í‘œì‹œ
    parser.print_help()
    print("\nğŸ’¡ í†µê³„ë¥¼ ë³´ë ¤ë©´: python3 cleanup.py --stats\n")
    print("ğŸ’¡ ìºì‹œ ì •ë¦¬: python3 cleanup.py --cache --days 7\n")


if __name__ == "__main__":
    main()
